{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn import tree\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()\n",
    "trainX[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labels\n",
    "Each training and test example is assigned to one of the following labels:\n",
    "\n",
    "| Label | Description |\n",
    "| --- | --- |\n",
    "| 0 | T-shirt/top |\n",
    "| 1 | Trouser |\n",
    "| 2 | Pullover |\n",
    "| 3 | Dress |\n",
    "| 4 | Coat |\n",
    "| 5 | Sandal |\n",
    "| 6 | Shirt |\n",
    "| 7 | Sneaker |\n",
    "| 8 | Bag |\n",
    "| 9 | Ankle boot |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(trainX[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainX.shape)\n",
    "trainX = trainX.reshape(len(trainX),28*28)\n",
    "print(trainX.shape)\n",
    "testX = testX.reshape(len(testX),28*28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.95)\n",
    "pca.fit(trainX)\n",
    "compressed_trainX = pca.transform(trainX)\n",
    "decompressed_trainX = pca.inverse_transform(compressed_trainX)\n",
    "compressed_testX = pca.transform(testX)\n",
    "decompressed_testX = pca.inverse_transform(compressed_testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"new shape:\",trainX.shape)\n",
    "plt.imshow(decompressed_trainX[0].reshape(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model):\n",
    "    model.fit(compressed_trainX, trainY)\n",
    "    y_pred = model.predict(compressed_trainX)\n",
    "    scores = cross_val_score(model,compressed_testX, testY, cv=10)\n",
    "    return(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "naive_bayes_model = GaussianNB()\n",
    "print(validate(naive_bayes_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc=SVC(probability=True, kernel='linear')#################come back to here!!!!!!!!!!##################\n",
    "adaboost_model=AdaBoostClassifier(tree.DecisionTreeClassifier(max_depth=5),n_estimators=50)\n",
    "print(validate(adaboost_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
    "print(validate(rnd_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=256, random_state=0).fit(compressed_trainX)\n",
    "\n",
    "def infer_data_labels(X_labels, cluster_labels):\n",
    "    predicted_labels = np.zeros(len(X_labels)).astype(np.uint8)\n",
    "    for i, cluster in enumerate(X_labels):\n",
    "        for key, value in cluster_labels.items():\n",
    "            if cluster in value:\n",
    "                predicted_labels[i] = key\n",
    "    return predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_cluster_labels(kmeans, actual_labels):\n",
    "    inferred_labels = {}\n",
    "    for i in range(kmeans.n_clusters):\n",
    "        labels = []\n",
    "        index = np.where(kmeans.labels_ == i)\n",
    "        labels.append(actual_labels[index])\n",
    "        if len(labels[0]) == 1:\n",
    "            counts = np.bincount(labels[0])#count the occurrence\n",
    "        else:\n",
    "            counts = np.bincount(np.squeeze(labels))\n",
    "        if np.argmax(counts) in inferred_labels:\n",
    "            inferred_labels[np.argmax(counts)].append(i)\n",
    "        else:\n",
    "            inferred_labels[np.argmax(counts)] = [i]\n",
    "    return inferred_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = infer_cluster_labels(kmeans, trainY)\n",
    "X_clusters = kmeans.predict(compressed_testX)\n",
    "predicted_labels = infer_data_labels(X_clusters, cluster_labels)\n",
    "metrics.accuracy_score(testY, predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = []\n",
    "for depth in range(2,200,3):\n",
    "    decision_tree = tree.DecisionTreeClassifier(random_state=0, max_depth=depth)\n",
    "    scores.append(validate(decision_tree))\n",
    "print(np.argmax(scores))\n",
    "#tree.plot_tree(decision_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.line(scores,range(2,800))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = trainX.reshape(trainX.shape[0], -1) / 255.0\n",
    "x_test = testX.reshape(testX.shape[0], -1) / 255.0\n",
    "y_train = to_categorical(trainY)\n",
    "y_test = to_categorical(testY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(10, input_dim=784, activation='relu'))#hidden layer\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))#output layer, Softmax - more than two categories,(Sigmoid - two categories)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#loss(multi-categories=categorical_crossentropy, two-categories=binary_crossentropy),optimizer(adam or rmsprop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.6469 - accuracy: 0.7694 - val_loss: 0.4826 - val_accuracy: 0.8298\n",
      "Epoch 2/10\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.4560 - accuracy: 0.8403 - val_loss: 0.4312 - val_accuracy: 0.8462\n",
      "Epoch 3/10\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.4196 - accuracy: 0.8505 - val_loss: 0.4142 - val_accuracy: 0.8503\n",
      "Epoch 4/10\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.3999 - accuracy: 0.8545 - val_loss: 0.4085 - val_accuracy: 0.8507\n",
      "Epoch 5/10\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.3879 - accuracy: 0.8584 - val_loss: 0.3933 - val_accuracy: 0.8570\n",
      "Epoch 6/10\n",
      "1688/1688 [==============================] - 2s 1ms/step - loss: 0.3754 - accuracy: 0.8632 - val_loss: 0.4103 - val_accuracy: 0.8488\n",
      "Epoch 7/10\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.3683 - accuracy: 0.8654 - val_loss: 0.3886 - val_accuracy: 0.8597\n",
      "Epoch 8/10\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.3626 - accuracy: 0.8674 - val_loss: 0.3798 - val_accuracy: 0.8622\n",
      "Epoch 9/10\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.3557 - accuracy: 0.8691 - val_loss: 0.3936 - val_accuracy: 0.8560\n",
      "Epoch 10/10\n",
      "1688/1688 [==============================] - 3s 2ms/step - loss: 0.3507 - accuracy: 0.8713 - val_loss: 0.3948 - val_accuracy: 0.8560\n",
      "313/313 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.8483\n",
      "0.8482999801635742\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=10, validation_split=0.1)\n",
    "_, test_acc = model.evaluate(x_test, y_test)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()\n",
    "x_train = trainX[:,:,:,np.newaxis] / 255.0\n",
    "x_test = testX[:,:,:,np.newaxis] / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "model4.add(Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(28,28, 1))) \n",
    "model4.add(MaxPooling2D(pool_size=2))\n",
    "model4.add(Flatten())\n",
    "model4.add(Dense(10, activation='softmax'))\n",
    "model4.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 64)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 12544)             0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 10)                125450    \n",
      "=================================================================\n",
      "Total params: 125,770\n",
      "Trainable params: 125,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "1688/1688 [==============================] - 52s 31ms/step - loss: 0.4316 - accuracy: 0.8513 - val_loss: 0.3379 - val_accuracy: 0.8787\n",
      "Epoch 2/10\n",
      "1688/1688 [==============================] - 48s 28ms/step - loss: 0.3101 - accuracy: 0.8910 - val_loss: 0.2973 - val_accuracy: 0.8943\n",
      "Epoch 3/10\n",
      "1688/1688 [==============================] - 45s 27ms/step - loss: 0.2807 - accuracy: 0.8992 - val_loss: 0.2878 - val_accuracy: 0.9003\n",
      "Epoch 4/10\n",
      "1688/1688 [==============================] - 48s 28ms/step - loss: 0.2610 - accuracy: 0.9061 - val_loss: 0.2898 - val_accuracy: 0.8963\n",
      "Epoch 5/10\n",
      "1688/1688 [==============================] - 52s 31ms/step - loss: 0.2429 - accuracy: 0.9142 - val_loss: 0.2957 - val_accuracy: 0.8955\n",
      "Epoch 6/10\n",
      "1688/1688 [==============================] - 50s 30ms/step - loss: 0.2305 - accuracy: 0.9170 - val_loss: 0.2724 - val_accuracy: 0.9030\n",
      "Epoch 7/10\n",
      "1688/1688 [==============================] - 57s 34ms/step - loss: 0.2173 - accuracy: 0.9240 - val_loss: 0.2662 - val_accuracy: 0.9067\n",
      "Epoch 8/10\n",
      "1688/1688 [==============================] - 46s 27ms/step - loss: 0.2054 - accuracy: 0.9265 - val_loss: 0.2745 - val_accuracy: 0.9032\n",
      "Epoch 9/10\n",
      "1688/1688 [==============================] - 46s 27ms/step - loss: 0.1961 - accuracy: 0.9296 - val_loss: 0.2859 - val_accuracy: 0.9020\n",
      "Epoch 10/10\n",
      "1688/1688 [==============================] - 46s 27ms/step - loss: 0.1884 - accuracy: 0.9329 - val_loss: 0.2754 - val_accuracy: 0.9022\n",
      "313/313 [==============================] - 3s 9ms/step - loss: 0.2947 - accuracy: 0.8999\n",
      "0.8999000191688538\n"
     ]
    }
   ],
   "source": [
    "model4.summary()\n",
    "model4.fit(x_train, y_train, epochs=10, validation_split=0.1)\n",
    "_, test_acc = model4.evaluate(x_test, y_test)\n",
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
